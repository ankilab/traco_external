{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a18a939",
   "metadata": {},
   "source": [
    "# TRACO example solution\n",
    "In this Jupyter Notebook we implemented a really simple approach of how to detect Hexbugs in a frame. The following steps are performed:\n",
    "- Load all videos and Hexbug positions for training\n",
    "- Resize all frames to a fixed size (target_shape)\n",
    "- Create a binary mask from the positions to train a U-Net\n",
    "- Create a simple neural network architecture\n",
    "- Get the final predictions by taking the maximum value (NOTE: We will always only find one Hexbug)\n",
    "- Convert the output to fit the \".csv\" format that is needed to use our score calculation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4540624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 19:53:14.368910: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 19:53:14.447714: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-24 19:53:14.826085: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /data/du92wufe/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-24 19:53:14.826126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /data/du92wufe/.local/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2023-04-24 19:53:14.826130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from segmentation_models.metrics import iou_score\n",
    "from segmentation_models.losses import dice_loss\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2bd2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path where the training data is located\n",
    "path_training_vids = Path(\"training\")\n",
    "\n",
    "# Downsample the input frames to a fixed target_shape\n",
    "target_shape = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65097154",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_train_videos(path):\n",
    "    \"\"\"\n",
    "    This function returns all trainings videos and the annotations as binary masks (1 at the positions where a Hexbug is located).\n",
    "    All frames are resized and normalized. \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for vid in os.listdir(path):\n",
    "        path = Path(path)\n",
    "        if \".mp4\" in vid:\n",
    "            with open(path / vid.replace(\"mp4\", \"traco\")) as f:\n",
    "                annotations = json.load(f)['rois']\n",
    "            \n",
    "            cap = cv2.VideoCapture(str(path / vid))\n",
    "            ret, frame = cap.read()     \n",
    "            org_shape = frame.shape\n",
    "            \n",
    "            z = 0  # frame counter\n",
    "            while ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                mask_frame = np.zeros(shape=target_shape)\n",
    "                for annot in annotations:\n",
    "                    if annot['z'] == z: \n",
    "                        # Get pos and scale it down to fit the target_shape\n",
    "                        pos = annot['pos']\n",
    "                        pos[0] = pos[0] * target_shape[0] // org_shape[1]\n",
    "                        pos[1] = pos[1] * target_shape[1] // org_shape[0]\n",
    "                        \n",
    "                        # Set the position if the Hexbug in the binary mask to 1\n",
    "                        try:\n",
    "                            mask_frame[int(pos[1]), int(pos[0])] = 1\n",
    "                        except:\n",
    "                            # IndexOutOfRange error sometimes occurs because of the downsampling of the frames\n",
    "                            mask_frame[int(pos[1]) - 1, int(pos[0]) - 1] = 1\n",
    "                        \n",
    "                # Resize the frame to the target size using bilinear interpolation\n",
    "                resized_frame = cv2.resize(frame, target_shape, interpolation=cv2.INTER_LINEAR)\n",
    "                \n",
    "                # Normalize to zero mean and unit variance\n",
    "                #normalized_frame = (resized_frame.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "                \n",
    "                # Append to lists\n",
    "                X.append(resized_frame)\n",
    "                Y.append(mask_frame) \n",
    "                \n",
    "                ret, frame = cap.read()  # read next frame\n",
    "                z += 1  # increase frame counter\n",
    "                \n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443b825",
   "metadata": {},
   "source": [
    "## Create and train U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e425feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 09:11:24.486943: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.492962: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.493979: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.495185: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-24 09:11:24.495833: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.496666: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.497449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.794897: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.795706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.796484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-24 09:11:24.797170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22310 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Input(shape=(target_shape[0], target_shape[1], 3)))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPool2D((2, 2)))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(UpSampling2D())\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv2D(filters=1, kernel_size=1, padding='same', activation='sigmoid'))\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),  # Define optimizer and learning rate\n",
    "              loss=dice_loss,                      # Dice loss function\n",
    "              metrics=[iou_score])     # Intersection over Union (IoU) & Dice score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d41d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 256, 256, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 256, 256, 32)      18464     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 256, 256, 1)       33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,889\n",
      "Trainable params: 37,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1d9b0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "X_train, Y_train = load_train_videos(path_training_vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0135beee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 09:11:52.277214: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n",
      "2023-04-24 09:11:52.860407: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-24 09:11:53.860932: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f8fc20e8cf0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-24 09:11:53.860950: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2023-04-24 09:11:53.863604: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-24 09:11:53.904033: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-04-24 09:11:53.941214: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "284/284 [==============================] - 18s 50ms/step - loss: 1.0000 - iou_score: 6.4461e-06 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 2/50\n",
      "284/284 [==============================] - 13s 45ms/step - loss: 1.0000 - iou_score: 1.8329e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 3/50\n",
      "284/284 [==============================] - 13s 46ms/step - loss: 1.0000 - iou_score: 1.8318e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 4/50\n",
      "284/284 [==============================] - 13s 46ms/step - loss: 1.0000 - iou_score: 1.8310e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 5/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8337e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 6/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8334e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 7/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8323e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 8/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8335e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 9/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8326e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 10/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8313e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 11/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8310e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 12/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8322e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 13/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8323e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 14/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8336e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 15/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8322e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 16/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8328e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 17/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8340e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 18/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8368e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 19/50\n",
      "284/284 [==============================] - 13s 48ms/step - loss: 1.0000 - iou_score: 1.8354e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 20/50\n",
      "284/284 [==============================] - 13s 48ms/step - loss: 1.0000 - iou_score: 1.8328e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 21/50\n",
      "284/284 [==============================] - 13s 48ms/step - loss: 1.0000 - iou_score: 1.8306e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 22/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8314e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 23/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8359e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 24/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8312e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 25/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8302e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 26/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8330e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 27/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8316e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 28/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8353e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 29/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8338e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 30/50\n",
      "284/284 [==============================] - 13s 47ms/step - loss: 1.0000 - iou_score: 1.8301e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 31/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8341e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 32/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8334e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 33/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8304e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 34/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8301e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 35/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8316e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 36/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8323e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 37/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8310e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 38/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8328e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 39/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8324e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 40/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8299e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 41/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8333e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 42/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8333e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 43/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8315e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 44/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8330e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 45/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8303e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 46/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8350e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 47/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8308e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 48/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8351e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 49/50\n",
      "284/284 [==============================] - 14s 48ms/step - loss: 1.0000 - iou_score: 1.8306e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n",
      "Epoch 50/50\n",
      "284/284 [==============================] - 13s 48ms/step - loss: 1.0000 - iou_score: 1.8348e-07 - val_loss: 1.0000 - val_iou_score: 2.3667e-07\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=Y_train, epochs=50, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5666a76e",
   "metadata": {},
   "source": [
    "## Apply the model to our test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "deb03355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_data(path):\n",
    "    \"\"\"\n",
    "    This function returns all validation videos, the original shapes of the videos and the filenames.\n",
    "    All frames are resized and normalized. \n",
    "    \"\"\"\n",
    "    X = []\n",
    "    org_shapes = []\n",
    "    file_names = []\n",
    "    \n",
    "    for vid in os.listdir(path):\n",
    "        path = Path(path)\n",
    "        if \".mp4\" in vid:\n",
    "            \n",
    "            cap = cv2.VideoCapture(str(path / vid))\n",
    "            ret, frame = cap.read()     \n",
    "            org_shape = frame.shape\n",
    "            \n",
    "            file_names.append(vid)\n",
    "            org_shapes.append(org_shape)\n",
    "            \n",
    "            X_ = []\n",
    "            while ret:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                        \n",
    "                # Resize the frame to the target size using bilinear interpolation\n",
    "                resized_frame = cv2.resize(frame, target_shape, interpolation=cv2.INTER_LINEAR)\n",
    "                \n",
    "                # Normalize to zero mean and unit variance\n",
    "                normalized_frame = (resized_frame.astype('float32') / 255.0 - 0.5) / 0.5\n",
    "                \n",
    "                # Append to lists\n",
    "                X_.append(normalized_frame)\n",
    "                \n",
    "                ret, frame = cap.read()  # read next frame\n",
    "            \n",
    "            X.append(np.asarray(X_))           \n",
    "    \n",
    "    return X, org_shapes, file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f8fbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get resized test frames, their original shapes and the filenames\n",
    "X_test, org_shapes, file_names = load_validation_data(\"leaderboard_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ba6b8",
   "metadata": {},
   "source": [
    "## Run the prediction and export your results in an appropriate way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "098d455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from export_tool import traco_to_csv, from_array_to_dict, save_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62ed0d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 12ms/step\n",
      "Saving to csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for idx, x in enumerate(X_test):\n",
    "    rois = []\n",
    "    \n",
    "    # Predict all frames of one video\n",
    "    preds = model.predict(x)\n",
    "    \n",
    "    # Get the original shape to scale the detected points back to fit the org_shape\n",
    "    org_shape = org_shapes[idx]\n",
    "    file_name = file_names[idx]\n",
    "    \n",
    "    # Iterate over the prediction of each image and determine the position of the maximum value\n",
    "    # Note: we find with this method of course only the position of a single HexBug\n",
    "    results = []\n",
    "    for frame_idx, pred in enumerate(preds):\n",
    "        pred = np.squeeze(pred)\n",
    "        pos = np.argwhere(pred == np.max(pred))[0]\n",
    "        \n",
    "        # Resize the positions back to original shape\n",
    "        pos[0] = int(pos[0] * org_shape[0] // target_shape[0])\n",
    "        pos[1] = int(pos[1] * org_shape[1] // target_shape[1])\n",
    "        \n",
    "        # Add an entry to the list of dicts\n",
    "        results = from_array_to_dict([frame_idx, 0, pos[1], pos[0]], results)\n",
    "\n",
    "    # Save results as .csv file\n",
    "    save_list(results, file_name.replace(\".mp4\", \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb8adc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>hexbug</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>535</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   t  hexbug    x     y\n",
       "0  0       0  535  1912\n",
       "1  1       0  535  1912\n",
       "2  2       0  535  1912\n",
       "3  3       0    0  1912\n",
       "4  4       0    0  1912"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f in os.listdir(\".\"):\n",
    "    if \".csv\" in f:\n",
    "        df = pd.read_csv(f, index_col=0)     \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38a7ed3",
   "metadata": {},
   "source": [
    "## Calculate final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "094e7dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_score import get_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e583bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for f in os.listdir(\".\"):\n",
    "    if \".csv\" in f:\n",
    "        # Calculate score --> will be zero as the files are the same\n",
    "        print(get_score(f, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f94eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
